{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class loss():\n",
    "\n",
    "    def calculate_loss(self, X, y):\n",
    "       loss = np.sum((X-y)**2)\n",
    "       return loss\n",
    "    \n",
    "    def calculate_grad(self,y_hat,y):\n",
    "        return (y_hat - y) / y_hat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear():\n",
    "    def __init__(self, n_in, n_out):\n",
    "        stdv = 1./np.sqrt(n_in)\n",
    "        self.W = np.random.uniform(-stdv, stdv, size = (n_in, n_out))\n",
    "        self.b = np.random.uniform(-stdv, stdv, size = n_out)\n",
    "\n",
    "        self.gradW = np.zeros_like(self.W)\n",
    "        self.gradb = np.zeros_like(self.b)\n",
    "\n",
    "    def forward(self,input):\n",
    "        return input @ self.W + self.b\n",
    "\n",
    "    def backward(self,gradOutput):\n",
    "        return gradOutput @ self.W.T\n",
    "\n",
    "    def accGradParameters(self, input, gradOutput):\n",
    "        self.gradb = np.sum(gradOutput, axis=0)\n",
    "        self.gradW = np.matmul(input.T, gradOutput)\n",
    "        \n",
    "        self.W -= 0.005 * self.gradW\n",
    "        self.b -= 0.005 * self.gradb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(500,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2441602.5102246776\n",
      "2405567.6917926706\n",
      "2352682.6788520403\n",
      "2264106.5821904005\n",
      "2113858.38614818\n",
      "1868731.5452489867\n",
      "1500842.3239337015\n",
      "1024109.6927412224\n",
      "538926.6828092001\n",
      "196645.17751064268\n",
      "48305.90057485379\n",
      "9795.72688395729\n",
      "2416.637722770322\n",
      "807.366348297742\n",
      "311.686801958252\n",
      "125.58065539512044\n",
      "51.20792581922747\n",
      "20.97844104945941\n",
      "8.620613454320836\n",
      "3.5522129907114706\n",
      "1.4676962692769906\n",
      "0.6080585480437946\n",
      "0.2525909395118331\n",
      "0.10520528247556209\n",
      "0.043932208034113365\n",
      "0.01839195330072095\n",
      "0.007718662488562761\n",
      "0.0032470790996534478\n",
      "0.0013691322909891624\n",
      "0.0005785796633053734\n"
     ]
    }
   ],
   "source": [
    "linear_1 = linear(3,4)\n",
    "linear_2 = linear(4,1)\n",
    "loss_f = loss()\n",
    "\n",
    "inp_1 = X\n",
    "\n",
    "for i in range(30):\n",
    "    out_1 = linear_1.forward(inp_1)\n",
    "    out_2 = linear_2.forward(out_1)\n",
    "\n",
    "    print(loss_f.calculate_loss(out_2, y))\n",
    "\n",
    "    grad_0 = loss_f.calculate_grad(out_2, y)\n",
    "    # print(f'grad_loss {grad_0.shape}')\n",
    "\n",
    "    grad_1 = linear_2.backward(grad_0)\n",
    "    # print(f'grad_2 {grad_1.shape}')\n",
    "\n",
    "    grad_2 = linear_1.backward(grad_1)\n",
    "    # print(f'grad_1 {grad_2.shape}')\n",
    "\n",
    "    linear_2.accGradParameters(out_1, grad_0)\n",
    "    linear_1.accGradParameters(inp_1, grad_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
